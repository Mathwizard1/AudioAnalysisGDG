{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Music genre classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from segment import OUTPUT_FOLDER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataExtractor:\n",
    "    def __init__(self, n_mfcc = 20):\n",
    "        self.n_mfcc = n_mfcc\n",
    "\n",
    "    def load_data(self, filename, genre):\n",
    "        self.genre = genre\n",
    "\n",
    "        self.y, self.sr = librosa.load(filename)\n",
    "        self.feature_extract()\n",
    "\n",
    "    def feature_extract(self):\n",
    "        # Tempo information\n",
    "        self.tempo = librosa.feature.tempo(y=self.y, sr=self.sr).round()\n",
    "\n",
    "        # Separate harmonic and percussive components, Tonnetz\n",
    "        self.y_harmonic, self.y_percussive = librosa.effects.hpss(self.y)\n",
    "        self.tonnetz = librosa.feature.tonnetz(y=self.y, sr=self.sr)\n",
    "\n",
    "        # Mathematical features\n",
    "        features_list = {}\n",
    "\n",
    "        features_list['tempo'] = [self.tempo.min(), self.tempo.mean(), self.tempo.max(), self.tempo.var()]\n",
    "        features_list['y_harmoic'] = [self.y_harmonic.min(), self.y_harmonic.mean(), self.y_harmonic.max(), self.y_harmonic.var()]\n",
    "        features_list['y_percussive'] = [self.y_percussive.min(), self.y_percussive.mean(), self.y_percussive.max(), self.y_percussive.var()]\n",
    "        features_list['tonnetz'] = [self.tonnetz.min(), self.tonnetz.mean(), self.tonnetz.max(), self.tonnetz.var()]\n",
    "\n",
    "        # Other Sound features\n",
    "        cstft=librosa.feature.chroma_stft(y=self.y, sr=self.sr)\n",
    "        features_list['cstft'] = [cstft.min(), cstft.mean(), cstft.max(), cstft.var()]\n",
    "\n",
    "        srms=librosa.feature.rms(y=self.y)\n",
    "        features_list['srms'] = [srms.min(), srms.mean(), srms.max(), srms.var()]\n",
    "\n",
    "        specband=librosa.feature.spectral_bandwidth(y=self.y, sr=self.sr)\n",
    "        features_list['specband'] = [specband.min(), specband.mean(), specband.max(), specband.var()]\n",
    "\n",
    "        speccent=librosa.feature.spectral_centroid(y=self.y, sr=self.sr)\n",
    "        features_list['speccent'] = [speccent.min(), speccent.mean(), speccent.max(), speccent.var()]\n",
    "\n",
    "        rolloff = librosa.feature.spectral_rolloff(y=self.y, sr=self.sr)\n",
    "        features_list['rolloff'] = [rolloff.min(), rolloff.mean(), rolloff.max(), rolloff.var()]\n",
    "\n",
    "        zero_crossing_rate = librosa.feature.zero_crossing_rate(y=self.y)\n",
    "        features_list['zero_crossing_rate'] = [zero_crossing_rate.min(), zero_crossing_rate.mean(), zero_crossing_rate.max(), zero_crossing_rate.var()]\n",
    "\n",
    "        mfcc = librosa.feature.mfcc(y=self.y, sr=self.sr, n_mfcc= self.n_mfcc)\n",
    "        for i in range(self.n_mfcc):\n",
    "            features_list[f'mfcc_{i}'] = [mfcc[i].min(), mfcc[i].mean(), mfcc[i].max(), mfcc[i].var()]\n",
    "\n",
    "        self.features_df = pd.DataFrame(features_list).transpose()\n",
    "        self.features_df.columns = ['min', 'mean', 'max', 'var']\n",
    "\n",
    "    def get_data(self, data_print = False):\n",
    "        # print the data  \n",
    "        if(data_print):\n",
    "            self.print_features()\n",
    "\n",
    "        # Get the dataframe with label\n",
    "        np_data = self.features_df.to_numpy()\n",
    "        np_data = np_data.reshape((1, 120))\n",
    "\n",
    "        return (np_data, self.genre)\n",
    "\n",
    "    def print_features(self):\n",
    "        print(f\"Genre: {self.genre}\")\n",
    "        print(f\"Tempo: {self.tempo}\")\n",
    "\n",
    "        print(self.features_df)\n",
    "\n",
    "    def plot_waveform(self):\n",
    "        # Plot\n",
    "        plt.figure(figsize=(14, 5))\n",
    "        librosa.display.waveshow(y= self.y, sr=self.sr)\n",
    "        plt.title(\"Waveform\")\n",
    "        plt.show()\n",
    "\n",
    "    def plot_tonnetz(self):\n",
    "        pass\n",
    "\n",
    "    def plot_Harmonic_Percussion(self):\n",
    "        # Plot\n",
    "        fig = plt.figure(figsize=(14, 5))\n",
    "        ax1 = fig.subplots() #Creates the Axis\n",
    "        ax2 = ax1.twinx()    #Creates twin axis\n",
    "\n",
    "        librosa.display.waveshow(self.y_harmonic, sr=self.sr, color='r', ax= ax1)\n",
    "        librosa.display.waveshow(self.y_percussive, sr=self.sr, color='b', ax = ax2)\n",
    "        plt.title(\"Harmonic and Percussive Component\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Genre: bengali\n",
      "Tempo: [99.]\n",
      "                           min         mean           max           var\n",
      "tempo                99.000000    99.000000     99.000000  0.000000e+00\n",
      "y_harmoic            -1.001796    -0.000002      0.995477  2.023340e-02\n",
      "y_percussive         -1.037359    -0.000128      1.043433  9.070307e-03\n",
      "tonnetz              -0.653017    -0.012017      0.653477  2.396049e-02\n",
      "cstft                 0.000000     0.324342      1.000000  9.598421e-02\n",
      "srms                  0.000000     0.152839      0.568597  1.512722e-02\n",
      "specband              0.000000  2522.219075   3843.048791  2.782880e+05\n",
      "speccent              0.000000  2339.426118   5839.908943  8.044558e+05\n",
      "rolloff               0.000000  5035.855931  10271.337891  4.493367e+06\n",
      "zero_crossing_rate    0.000000     0.098357      0.450684  3.068565e-03\n",
      "mfcc_0             -461.054596  -134.229691     49.051128  8.494335e+03\n",
      "mfcc_1              -59.865063    82.586563    195.069305  1.313935e+03\n",
      "mfcc_2              -72.737030    -3.729473     95.656998  4.518024e+02\n",
      "mfcc_3              -66.504608     1.492128     64.884308  3.820363e+02\n",
      "mfcc_4              -56.051842    -7.456115     52.736267  2.867196e+02\n",
      "mfcc_5              -62.657627   -13.535247     32.099350  2.356376e+02\n",
      "mfcc_6              -52.378761    -6.015238     49.548508  2.046421e+02\n",
      "mfcc_7              -49.196259    -8.922787     32.312309  1.934660e+02\n",
      "mfcc_8              -64.989304   -16.698929     19.781736  1.966448e+02\n",
      "mfcc_9              -36.170101     3.785423     51.325462  1.948549e+02\n",
      "mfcc_10             -44.479988    -7.778539     33.749973  1.269492e+02\n",
      "mfcc_11             -35.419151    -5.907148     31.059237  1.120942e+02\n",
      "mfcc_12             -35.358505    -2.896004     37.687737  1.129688e+02\n",
      "mfcc_13             -39.123653    -0.926355     41.640915  1.106769e+02\n",
      "mfcc_14             -39.232399    -7.150599     26.353449  1.024247e+02\n",
      "mfcc_15             -29.359480     1.938903     41.415573  9.344137e+01\n",
      "mfcc_16             -39.627632    -7.059954     22.681793  8.291782e+01\n",
      "mfcc_17             -33.682644    -4.539728     29.077946  9.395689e+01\n",
      "mfcc_18             -46.520691    -9.949609     25.923035  8.871941e+01\n",
      "mfcc_19             -31.269131     1.395617     34.484215  7.363921e+01\n"
     ]
    }
   ],
   "source": [
    "DataExtrc = DataExtractor()\n",
    "\n",
    "DataExtrc.load_data(r'data\\bengal\\bengali1_fullsong.mp3', 'bengali')\n",
    "DataExtrc.print_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class DataExtractor:\n",
    "#     # Multiprocessing\n",
    "#     lock = multiprocessing.Lock()\n",
    "\n",
    "#     # Librosa predefined features\n",
    "#     feature_functions = {}\n",
    "#     feature_functions['harmonic'] = librosa.effects.harmonic\n",
    "#     feature_functions['percussive'] = librosa.effects.percussive\n",
    "\n",
    "#     feature_functions['tempo'] = librosa.feature.chroma_stft\n",
    "#     feature_functions['tonnnetz'] = librosa.feature.tonnetz\n",
    "#     feature_functions['cstft'] = librosa.feature.chroma_stft\n",
    "#     feature_functions['rms'] = librosa.feature.rms\n",
    "#     feature_functions['spec_band'] = librosa.feature.spectral_bandwidth\n",
    "#     feature_functions['spec_cent'] = librosa.feature.spectral_centroid\n",
    "#     feature_functions['spec_rolloff'] = librosa.feature.spectral_rolloff\n",
    "#     feature_functions['zero_cr'] = librosa.feature.zero_crossing_rate\n",
    "#     feature_functions['mfcc'] = librosa.feature.mfcc\n",
    "\n",
    "#     def __init__(self, n_mfcc = 20):\n",
    "#         self.n_mfcc = n_mfcc\n",
    "\n",
    "#     def load_data(self, filename, genre):\n",
    "#         self.genre = genre\n",
    "\n",
    "#         self.y, self.sr = librosa.load(filename)\n",
    "#         self.feature_extract()\n",
    "\n",
    "#     def feature_extract(self):\n",
    "#         processes = []\n",
    "\n",
    "#         # Mathematical features\n",
    "#         features_list = {}\n",
    "#         for key in list(self.feature_functions.keys()):\n",
    "#             p = multiprocessing.Process(target= self.parallel_extract, args= (key, features_list))\n",
    "            \n",
    "#             processes.append(p)\n",
    "#             p.start()\n",
    "\n",
    "#         for p in processes:\n",
    "#             p.join()\n",
    "\n",
    "#         print(features_list)\n",
    "#         # self.features_df = pd.DataFrame(features_list).transpose()\n",
    "#         # self.features_df.columns = ['min', 'mean', 'max', 'var']\n",
    "\n",
    "#     # For features\n",
    "#     # Special case for mfcc\n",
    "#     def parallel_extract(self, feature_name, features_list):\n",
    "#         feature_data = self.feature_functions[feature_name](self.y, self.sr)\n",
    "\n",
    "#         # store in same features using lock\n",
    "#         with self.lock():\n",
    "#             if(feature_name != 'mfcc'):\n",
    "#                 features_list[feature_name] = [feature_data.min(), feature_data.mean(), \n",
    "#                                                feature_data.max(), feature_data.var()]\n",
    "#             else:\n",
    "#                 print('mfcc time')\n",
    "\n",
    "\n",
    "#     def get_data(self, data_print = False):\n",
    "#         # print the data  \n",
    "#         if(data_print):\n",
    "#             self.print_features()\n",
    "\n",
    "#         # Get the dataframe with label\n",
    "#         np_data = self.features_df.to_numpy()\n",
    "#         np_data = np_data.reshape((1, 120))\n",
    "\n",
    "#         return (np_data, self.genre)\n",
    "\n",
    "#     def print_features(self):\n",
    "#         print(f\"Genre: {self.genre}\")\n",
    "#         print(f\"Tempo: {self.tempo}\")\n",
    "\n",
    "#         print(self.features_df)\n",
    "\n",
    "#     def plot_waveform(self):\n",
    "#         # Plot\n",
    "#         plt.figure(figsize=(14, 5))\n",
    "#         librosa.display.waveshow(y= self.y, sr=self.sr)\n",
    "#         plt.title(\"Waveform\")\n",
    "#         plt.show()\n",
    "\n",
    "#     def plot_tonnetz(self):\n",
    "#         pass\n",
    "\n",
    "#     def plot_Harmonic_Percussion(self):\n",
    "#         # Plot\n",
    "#         fig = plt.figure(figsize=(14, 5))\n",
    "#         ax1 = fig.subplots() #Creates the Axis\n",
    "#         ax2 = ax1.twinx()    #Creates twin axis\n",
    "\n",
    "\n",
    "#         librosa.display.waveshow(y_harmonic, sr=self.sr, color='r', ax= ax1)\n",
    "#         librosa.display.waveshow(y_percussive, sr=self.sr, color='b', ax = ax2)\n",
    "#         plt.title(\"Harmonic and Percussive Component\")\n",
    "#         plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataExtrc = DataExtractor()\n",
    "\n",
    "# DataExtrc.load_data(r'data\\bengal\\bengali1_fullsong.mp3', 'bengali')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 120)\n"
     ]
    }
   ],
   "source": [
    "np_data, genre = DataExtrc.get_data()\n",
    "print(np_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "datapath= OUTPUT_FOLDER\n",
    "genres, num_genre = None, 0\n",
    "\n",
    "try:\n",
    "    genres= sorted(os.listdir(datapath))\n",
    "    num_genre = len(genres)\n",
    "    print(num_genre)\n",
    "except:\n",
    "    print(\"No folder found\")\n",
    "    print(\"Run segment.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# Torch\n",
    "MY_DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(MY_DEVICE)\n",
    "\n",
    "SAVE_MODEL = False\n",
    "\n",
    "D_TYPE = torch.float\n",
    "\n",
    "# Training Parameters\n",
    "LEARNING_RATE = 1e-3\n",
    "WEIGHT_DECAY = 0.001\n",
    "\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 2\n",
    "\n",
    "RAND_SHUFFLE = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class genreDataSet(Dataset):\n",
    "    n_mfcc = 20\n",
    "\n",
    "    def __init__(self, dataPath):\n",
    "        super().__init__()\n",
    "\n",
    "        self.data_extractor = DataExtractor(self.n_mfcc)\n",
    "        self.label = []\n",
    "        self.X = []\n",
    "\n",
    "        self.genres = sorted(os.listdir(datapath))\n",
    "        self.num_genres = len(self.genres)\n",
    "\n",
    "        for genre in genres:\n",
    "            genre_path = os.path.join(datapath, genre)\n",
    "            # print(\"Genre:\",genre)\n",
    "            for _,_,files in os.walk(genre_path):\n",
    "                for file in files:\n",
    "                    # print(file)\n",
    "                    \n",
    "                    self.data_extractor.load_data(dataPath + '/' + genre + '/' + file, genre)\n",
    "                    x, x_label = self.data_extractor.get_data()\n",
    "\n",
    "                    self.label.append(x_label)\n",
    "                    self.X.append(x)\n",
    "\n",
    "        self.length = len(self.label)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        label = self.label[index]\n",
    "        X = self.X[index]\n",
    "\n",
    "        one_hot = torch.zeros(self.num_genres, dtype= D_TYPE)\n",
    "        if label in self.genres:\n",
    "            hot_index = self.genres.index(label)\n",
    "        one_hot[hot_index] = 1\n",
    "\n",
    "        return (\n",
    "            torch.tensor(X, dtype= D_TYPE),\n",
    "            one_hot\n",
    "        )\n",
    "    \n",
    "genre_loader = DataLoader(genreDataSet(datapath), \n",
    "                          batch_size= BATCH_SIZE, shuffle= RAND_SHUFFLE,\n",
    "                          \n",
    "                          # experimental for gpu\n",
    "                          # pin_memory= True\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################\n",
    "# Model parameters\n",
    "\n",
    "IN_DIM = 120\n",
    "EMBED_DIM = 64\n",
    "\n",
    "###############################\n",
    "class GenreClassifier(nn.Module):\n",
    "    name = \"GenreClassifier.pth\"\n",
    "\n",
    "    base_dim_med = 64\n",
    "    base_dim_large = 128\n",
    "\n",
    "    num_heads = 4\n",
    "    drop_out = 0.1\n",
    "\n",
    "    def load_model(self):\n",
    "        self.load_state_dict(torch.load(self.name, weights_only= True))\n",
    "\n",
    "    def __init__(self, indim, embed_dim, outdim):\n",
    "        super().__init__()\n",
    "\n",
    "        self.indim = indim\n",
    "        self.embed_dim = embed_dim\n",
    "        self.outdim = outdim\n",
    "\n",
    "        self.transform_layer = nn.Sequential(\n",
    "             # Transform pass\n",
    "             nn.Linear(self.indim, self.embed_dim),\n",
    "             nn.LayerNorm(self.embed_dim)\n",
    "        )\n",
    "\n",
    "        self.self_attention_layer = nn.MultiheadAttention(self.embed_dim, self.num_heads, batch_first= True)\n",
    "\n",
    "        self.base_layers= nn.Sequential(\n",
    "            nn.LayerNorm(self.embed_dim),\n",
    "            nn.Dropout(self.drop_out),\n",
    "            \n",
    "            # Deep pass 1\n",
    "            nn.Linear(self.embed_dim, self.base_dim_large),\n",
    "            nn.Dropout(self.drop_out),\n",
    "            nn.ReLU(self.base_dim_large),\n",
    "            \n",
    "            # Deep Pass 2\n",
    "            nn.Linear(self.base_dim_large, self.base_dim_med),\n",
    "            nn.Dropout(self.drop_out),\n",
    "            nn.ReLU(self.base_dim_med),\n",
    "\n",
    "            # Final Pass\n",
    "            nn.Linear(self.base_dim_med, self.outdim),\n",
    "            nn.Softmax(dim= -1)\n",
    "        )\n",
    "\n",
    "    # For debug\n",
    "    '''def forward(self, x):\n",
    "        print(x.shape)\n",
    "        \n",
    "        for layer in self.transform_layer:\n",
    "            x = layer(x)\n",
    "            print(x.shape, layer.type)\n",
    "\n",
    "        x_attn, _ = self.self_attention_layer(x, x, x)\n",
    "        print(x_attn.shape, self.self_attention_layer.type)\n",
    "\n",
    "        for layer in self.base_layers:\n",
    "            x = layer(x)\n",
    "            print(x.shape, layer.type)\n",
    "\n",
    "        return x'''\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.transform_layer(x)\n",
    "\n",
    "        x_attn, _ = self.self_attention_layer(x, x, x)\n",
    "\n",
    "        # Self Normalisation (for experiments)\n",
    "        # x_attn = x_attn + x\n",
    "\n",
    "        return self.base_layers(x_attn)\n",
    "    \n",
    "model = GenreClassifier(IN_DIM, EMBED_DIM, num_genre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5372, 0.4628]], grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "output = model(torch.tensor(np_data, dtype= D_TYPE))\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.RMSprop(model.parameters(), lr= LEARNING_RATE, weight_decay= WEIGHT_DECAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.6965186297893524\n",
      "Epoch [2/10], Loss: 0.7266868054866791\n",
      "Epoch [3/10], Loss: 0.6118471920490265\n",
      "Epoch [4/10], Loss: 0.5707031786441803\n",
      "Epoch [5/10], Loss: 0.5687529891729355\n",
      "Epoch [6/10], Loss: 0.5750177502632141\n",
      "Epoch [7/10], Loss: 0.5689035654067993\n",
      "Epoch [8/10], Loss: 0.5701285004615784\n",
      "Epoch [9/10], Loss: 0.5610448569059372\n",
      "Epoch [10/10], Loss: 0.5720008909702301\n"
     ]
    }
   ],
   "source": [
    "# Training function\n",
    "def train_model(model: GenreClassifier, dataloader: DataLoader, num_epochs):\n",
    "    model.to(MY_DEVICE)\n",
    "    model.train()  # Set model to train mode\n",
    "\n",
    "    least_loss = torch.inf\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        for (genre_data, genre) in dataloader:\n",
    "\n",
    "            # Send to Device\n",
    "            Xs = genre_data.squeeze(1).to(MY_DEVICE)\n",
    "            labels = genre.squeeze(1).to(MY_DEVICE)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(Xs)\n",
    "            \n",
    "            # print(outputs, type(outputs))\n",
    "            # print(labels, type(labels))\n",
    "            # print(outputs.shape, labels.shape)\n",
    "\n",
    "            # Loss\n",
    "            loss = criterion(outputs, labels)\n",
    "            # print(loss)\n",
    "\n",
    "            # Zero the gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Backward pass and optimization\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        # Print loss at the end of epoch\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(dataloader)}\")\n",
    "\n",
    "        # Save model at the end of each epoch (best only)\n",
    "        if(running_loss <= least_loss and SAVE_MODEL):\n",
    "            least_loss = running_loss\n",
    "            torch.save(model.state_dict(), model.name)\n",
    "            print(f\"Model saved after epoch {epoch+1}\")\n",
    "\n",
    "# Train the model\n",
    "train_model(model, genre_loader, num_epochs= EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(genreDataSet(datapath), batch_size= 1)\n",
    "model = GenreClassifier(IN_DIM, EMBED_DIM, num_genre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: bengal, label: bengal\n",
      "tensor(0.6661, grad_fn=<DivBackward1>)\n",
      "model: bengal, label: bengal\n",
      "tensor(0.6652, grad_fn=<DivBackward1>)\n",
      "model: bengal, label: bengal\n",
      "tensor(0.6659, grad_fn=<DivBackward1>)\n",
      "model: bengal, label: tamilnadu\n",
      "tensor(0.7217, grad_fn=<DivBackward1>)\n"
     ]
    }
   ],
   "source": [
    "# Test function\n",
    "def test_model(model: GenreClassifier, dataloader: DataLoader):\n",
    "    model.to(MY_DEVICE)\n",
    "    model.eval()  \n",
    "\n",
    "    for (genre_data, genre) in dataloader:\n",
    "        # Send to Device\n",
    "        Xs = genre_data.squeeze(1).to(MY_DEVICE)\n",
    "        labels = genre.squeeze(1).to(MY_DEVICE)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(Xs)\n",
    "\n",
    "        # Loss\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        pred = outputs.argmax(dim=-1).item()\n",
    "        actual = labels.argmax(dim=-1).item()\n",
    "\n",
    "        print(f\"model: {genres[pred]}, label: {genres[actual]}\")\n",
    "        print(loss)\n",
    "\n",
    "# load weights if exists\n",
    "if(os.path.exists(model.name)):\n",
    "    model.load_model()\n",
    "\n",
    "test_model(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import AutoProcessor, MusicgenForConditionalGeneration\n",
    "# from transformers import Trainer, TrainingArguments\n",
    "\n",
    "# from peft import LoraConfig, get_peft_model\n",
    "\n",
    "# model_id = \"facebook/musicgen-small\"\n",
    "# mydevice = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processor\n",
    "# processor = AutoProcessor.from_pretrained(model_id)\n",
    "\n",
    "# Model\n",
    "# model = MusicgenForConditionalGeneration.from_pretrained(model_id)\n",
    "\n",
    "# print(f\"Memory footprint: {model.get_memory_footprint() / 1e6:.2f} MB\")\n",
    "# print(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
